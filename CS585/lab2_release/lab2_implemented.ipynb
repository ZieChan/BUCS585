{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E_OfJPZDTcRH"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "CS585 Image and Video Computing\n",
    "Lab 2 Part I\n",
    "--------------\n",
    "This program introduces the following concepts:\n",
    "a) Finding objects in a binary image\n",
    "b) Filtering objects based on size\n",
    "c) Obtaining information about the objects described by their contours\n",
    "--------------\n",
    "'''\n",
    "\n",
    "# Global variables\n",
    "thresh = 128\n",
    "max_thresh = 255\n",
    "\n",
    "# OpenCV at this moment (2024) is a tricky thing to learn, but very convenient tool for \"quick\" image proccessing. When compared to deep-learning-focused libraries such as Pytorch or Huggingface,\n",
    "# OpenCV is more CV-oriented, and provide a lot of straightforward image processing algorithms that are easy to implement (if you are familiar with them). So it is very good for testing simple ideas for complicated stuff.\n",
    "# The downside is, OpenCV is mostly C/C++ based, and merely developed to support Python. Consequently, it's hard to learn how certain things in OpenCV if without looking into the C/C++ code\n",
    "# from OpenCV. Also, certain amount of algorithms in OpenCV are \"classic\" algorithms, which are not the so-called \"state-of-the-art\" algorithms anymore, so personally I don't recommend\n",
    "# spending too much time to understand them in a source code level. Therefore, in this lab, we are going to utilize as much online resources as possible to get the \"code\" things done while\n",
    "# spending more time on the ideas of the algorithms and specific CV problems themselves. The purpose of the lab is to get the \"code\" thing done as quickly as possible, and leave enough time\n",
    "# for you to think about more high-level problem about computer vision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "D0uJTsMwVUlS",
    "outputId": "b992214b-6f8f-4cce-cd58-3fd060e65412"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow\n\u001b[1;32m      5\u001b[0m thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m      6\u001b[0m max_thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "thresh = 128\n",
    "max_thresh = 255\n",
    "\n",
    "def show_image(cv_image):\n",
    "  # different ways of displaying a opencv image other than using opencv itself\n",
    "  # https://www.geeksforgeeks.org/how-to-display-an-opencv-image-in-python-with-matplotlib/ matplotlib\n",
    "  # https://www.geeksforgeeks.org/convert-opencv-image-to-pil-image-in-python/ Pillow\n",
    "\n",
    "  cv2_imshow(cv_image)\n",
    "\n",
    "def thresholding(image_cv_gray):\n",
    "  # an example to do thresholding\n",
    "  # https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html\n",
    "  _, thres_output = cv2.threshold(image_cv_gray, thresh, max_thresh, 0)\n",
    "  return thres_output\n",
    "\n",
    "def get_contours(cv_image_thres):\n",
    "  # an example how to detect and draw contours found in an image\n",
    "  # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\n",
    "\n",
    "  # double check the interfaces are consistent for the latest opencv version\n",
    "  # https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga95f5b48d01abc7c2e0732db24689837b\n",
    "\n",
    "  contours, hierarchy = cv2.findContours(cv_image_thres, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  return contours\n",
    "def draw_contours(cv_image, contours,fill='line'):\n",
    "  # an example how to detect and draw contours found in an image\n",
    "  # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\n",
    "\n",
    "  # double check the interfaces are consistent for the latest opencv version\n",
    "  # https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc\n",
    "\n",
    "  # fill the contour instead of just draw the line:\n",
    "  # https://stackoverflow.com/questions/19222343/filling-contours-with-opencv-python\n",
    "  if fill=='solid':\n",
    "    cv_image_out = cv2.drawContours(cv_image, contours, -1,(0,255,0),cv2.FILLED)\n",
    "  else:\n",
    "    cv_image_out = cv2.drawContours(cv_image, contours, -1,(0,255,0),1)\n",
    "  return cv_image_out\n",
    "\n",
    "def get_largest_contour(contours):\n",
    "  # https://stackoverflow.com/questions/8369547/checking-contour-area-in-opencv-using-python\n",
    "  max_area = 0\n",
    "  max_i = -1\n",
    "  for i,contour in enumerate(contours):\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > max_area:\n",
    "      max_i = i\n",
    "      max_area = area\n",
    "  return [contours[max_i]]\n",
    "\n",
    "def init_canvas(size,mode='color'):\n",
    "  # if we observe the type of openCV-read image data,\n",
    "  # the quickest way is to simply create a all-zero ndarray\n",
    "  cols,rows = size\n",
    "  if mode == 'color':\n",
    "    canvas = np.zeros((rows,cols,3))\n",
    "  elif mode == 'grayscale':\n",
    "    canvas = np.zeros((rows,cols))\n",
    "  elif mode == 'binary':\n",
    "    canvas = np.zeros((rows,cols)).astype(np.uint8)\n",
    "  else:\n",
    "    raise NotImplementedError\n",
    "  return canvas\n",
    "\n",
    "# check here to see how to pre-process:\n",
    "# https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\n",
    "image_cv = cv2.imread(\"hand.jpg\", cv2.IMREAD_COLOR)\n",
    "image_cv_gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
    "image_cv_blur = cv2.blur(image_cv_gray, (3, 3))\n",
    "image_cv_threhold = thresholding(image_cv_blur)\n",
    "\n",
    "# Mind the document says that\n",
    "# \"Source, an 8-bit single-channel image. Non-zero pixels are treated as 1's. Zero pixels remain 0's, so the image is treated as binary .\n",
    "# so you need a binary formatted image to get contours\n",
    "contours = get_contours(image_cv_threhold)\n",
    "\n",
    "max_contour = get_largest_contour(contours)\n",
    "\n",
    "canvas = init_canvas((image_cv_gray.shape[1],image_cv_gray.shape[0]))\n",
    "image_cv_out = draw_contours(image_cv,contours)\n",
    "\n",
    "show_image(image_cv_out)\n",
    "\n",
    "# what is not covered (but you should try to make your life eaiser for coding assignment)\n",
    "# Documentation for createTrackbar: http://docs.opencv.org/modules/highgui/doc/user_interface.html?highlight=createtrackbar#createtrackbar\n",
    "# Example of adding a trackbar: http://docs.opencv.org/doc/tutorials/highgui/trackbar/trackbar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "id": "yvqAMsTETcRM",
    "outputId": "f48aca2c-845c-4c09-83fd-d91250fc8c38"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=640x480>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=640x480>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def morph_image(image,morph, kernel_size):\n",
    "  # modify the code from here:\n",
    "  # https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html this example is too complicated which I don't like it, but still worth taking a look.\n",
    "  # https://pyimagesearch.com/2021/04/28/opencv-morphological-operations/ a more straightfoward example, but miss details that might be interesting to you.\n",
    "\n",
    "  def erosion(image_cv, kernel_size = 4):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))\n",
    "    image_cv_eroded = cv2.erode(image_cv, kernel)\n",
    "    return image_cv_eroded\n",
    "  def dilate(image_cv, kernel_size = 4):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))\n",
    "    image_cv_dilated = cv2.dilate(image_cv, kernel)\n",
    "    return image_cv_dilated\n",
    "  if morph == 'dilate':\n",
    "    image_morphed = dilate(image,kernel_size = kernel_size)\n",
    "  elif morph == 'erode':\n",
    "    image_morphed = erosion(image,kernel_size = kernel_size)\n",
    "  else:\n",
    "    raise NotImplementedError\n",
    "  return image_morphed\n",
    "\n",
    "image_cv = cv2.imread(\"blob.png\", cv2.IMREAD_COLOR)\n",
    "image_cv_gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
    "_, image_binary = cv2.threshold(image_cv_gray, 0.0, 255.0, cv2.THRESH_BINARY)\n",
    "# image_morphed = morph_image(morph_image(image_binary,morph='erode', kernel_size=2),morph='dilate',kernel_size=10)\n",
    "image_morphed = morph_image(image_binary,morph='erode', kernel_size=100)\n",
    "morphed_contours = get_contours(image_morphed)\n",
    "image_cv_out = draw_contours(image_cv,morphed_contours,fill='solid')\n",
    "\n",
    "show_image(image_binary)\n",
    "print(\"\")\n",
    "show_image(image_cv_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fN3IcuP2mq72"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
