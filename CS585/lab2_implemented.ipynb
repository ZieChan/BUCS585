{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E_OfJPZDTcRH"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "CS585 Image and Video Computing\n",
    "Lab 2 Part I\n",
    "--------------\n",
    "This program introduces the following concepts:\n",
    "a) Finding objects in a binary image\n",
    "b) Filtering objects based on size\n",
    "c) Obtaining information about the objects described by their contours\n",
    "--------------\n",
    "'''\n",
    "\n",
    "# Global variables\n",
    "thresh = 128\n",
    "max_thresh = 255\n",
    "\n",
    "# OpenCV at this moment (2024) is a tricky thing to learn, but very convenient tool for \"quick\" image proccessing. When compared to deep-learning-focused libraries such as Pytorch or Huggingface,\n",
    "# OpenCV is more CV-oriented, and provide a lot of straightforward image processing algorithms that are easy to implement (if you are familiar with them). So it is very good for testing simple ideas for complicated stuff.\n",
    "# The downside is, OpenCV is mostly C/C++ based, and merely developed to support Python. Consequently, it's hard to learn how certain things in OpenCV if without looking into the C/C++ code\n",
    "# from OpenCV. Also, certain amount of algorithms in OpenCV are \"classic\" algorithms, which are not the so-called \"state-of-the-art\" algorithms anymore, so personally I don't recommend\n",
    "# spending too much time to understand them in a source code level. Therefore, in this lab, we are going to utilize as much online resources as possible to get the \"code\" things done while\n",
    "# spending more time on the ideas of the algorithms and specific CV problems themselves. The purpose of the lab is to get the \"code\" thing done as quickly as possible, and leave enough time\n",
    "# for you to think about more high-level problem about computer vision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "D0uJTsMwVUlS",
    "outputId": "b992214b-6f8f-4cce-cd58-3fd060e65412"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.016] global loadsave.cpp:248 findDecoder imread_('hand.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# check here to see how to pre-process:\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\u001b[39;00m\n\u001b[1;32m     72\u001b[0m image_cv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhand.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m---> 73\u001b[0m image_cv_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image_cv, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     74\u001b[0m image_cv_blur \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mblur(image_cv_gray, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     75\u001b[0m image_cv_threhold \u001b[38;5;241m=\u001b[39m thresholding(image_cv_blur)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "thresh = 128\n",
    "max_thresh = 255\n",
    "\n",
    "def show_image(cv_image):\n",
    "  # different ways of displaying a opencv image other than using opencv itself\n",
    "  # https://www.geeksforgeeks.org/how-to-display-an-opencv-image-in-python-with-matplotlib/ matplotlib\n",
    "  # https://www.geeksforgeeks.org/convert-opencv-image-to-pil-image-in-python/ Pillow\n",
    "\n",
    "  cv2_imshow(cv_image)\n",
    "\n",
    "def thresholding(image_cv_gray):\n",
    "  # an example to do thresholding\n",
    "  # https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html\n",
    "  _, thres_output = cv2.threshold(image_cv_gray, thresh, max_thresh, 0)\n",
    "  return thres_output\n",
    "\n",
    "def get_contours(cv_image_thres):\n",
    "  # an example how to detect and draw contours found in an image\n",
    "  # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\n",
    "\n",
    "  # double check the interfaces are consistent for the latest opencv version\n",
    "  # https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga95f5b48d01abc7c2e0732db24689837b\n",
    "\n",
    "  contours, hierarchy = cv2.findContours(cv_image_thres, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  return contours\n",
    "def draw_contours(cv_image, contours,fill='line'):\n",
    "  # an example how to detect and draw contours found in an image\n",
    "  # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\n",
    "\n",
    "  # double check the interfaces are consistent for the latest opencv version\n",
    "  # https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc\n",
    "\n",
    "  # fill the contour instead of just draw the line:\n",
    "  # https://stackoverflow.com/questions/19222343/filling-contours-with-opencv-python\n",
    "  if fill=='solid':\n",
    "    cv_image_out = cv2.drawContours(cv_image, contours, -1,(0,255,0),cv2.FILLED)\n",
    "  else:\n",
    "    cv_image_out = cv2.drawContours(cv_image, contours, -1,(0,255,0),1)\n",
    "  return cv_image_out\n",
    "\n",
    "def get_largest_contour(contours):\n",
    "  # https://stackoverflow.com/questions/8369547/checking-contour-area-in-opencv-using-python\n",
    "  max_area = 0\n",
    "  max_i = -1\n",
    "  for i,contour in enumerate(contours):\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > max_area:\n",
    "      max_i = i\n",
    "      max_area = area\n",
    "  return [contours[max_i]]\n",
    "\n",
    "def init_canvas(size,mode='color'):\n",
    "  # if we observe the type of openCV-read image data,\n",
    "  # the quickest way is to simply create a all-zero ndarray\n",
    "  cols,rows = size\n",
    "  if mode == 'color':\n",
    "    canvas = np.zeros((rows,cols,3))\n",
    "  elif mode == 'grayscale':\n",
    "    canvas = np.zeros((rows,cols))\n",
    "  elif mode == 'binary':\n",
    "    canvas = np.zeros((rows,cols)).astype(np.uint8)\n",
    "  else:\n",
    "    raise NotImplementedError\n",
    "  return canvas\n",
    "\n",
    "# check here to see how to pre-process:\n",
    "# https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\n",
    "image_cv = cv2.imread(\"hand.jpg\", cv2.IMREAD_COLOR)\n",
    "image_cv_gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
    "image_cv_blur = cv2.blur(image_cv_gray, (3, 3))\n",
    "image_cv_threhold = thresholding(image_cv_blur)\n",
    "\n",
    "# Mind the document says that\n",
    "# \"Source, an 8-bit single-channel image. Non-zero pixels are treated as 1's. Zero pixels remain 0's, so the image is treated as binary .\n",
    "# so you need a binary formatted image to get contours\n",
    "contours = get_contours(image_cv_threhold)\n",
    "\n",
    "max_contour = get_largest_contour(contours)\n",
    "\n",
    "canvas = init_canvas((image_cv_gray.shape[1],image_cv_gray.shape[0]))\n",
    "image_cv_out = draw_contours(image_cv,contours)\n",
    "\n",
    "show_image(image_cv_out)\n",
    "\n",
    "# what is not covered (but you should try to make your life eaiser for coding assignment)\n",
    "# Documentation for createTrackbar: http://docs.opencv.org/modules/highgui/doc/user_interface.html?highlight=createtrackbar#createtrackbar\n",
    "# Example of adding a trackbar: http://docs.opencv.org/doc/tutorials/highgui/trackbar/trackbar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "id": "yvqAMsTETcRM",
    "outputId": "f48aca2c-845c-4c09-83fd-d91250fc8c38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@4310.071] global loadsave.cpp:248 findDecoder imread_('blob.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m image_morphed\n\u001b[1;32m     22\u001b[0m image_cv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblob.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m---> 23\u001b[0m image_cv_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image_cv, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     24\u001b[0m _, image_binary \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(image_cv_gray, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m255.0\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# image_morphed = morph_image(morph_image(image_binary,morph='erode', kernel_size=2),morph='dilate',kernel_size=10)\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "def morph_image(image,morph, kernel_size):\n",
    "  # modify the code from here:\n",
    "  # https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html this example is too complicated which I don't like it, but still worth taking a look.\n",
    "  # https://pyimagesearch.com/2021/04/28/opencv-morphological-operations/ a more straightfoward example, but miss details that might be interesting to you.\n",
    "\n",
    "  def erosion(image_cv, kernel_size = 4):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))\n",
    "    image_cv_eroded = cv2.erode(image_cv, kernel)\n",
    "    return image_cv_eroded\n",
    "  def dilate(image_cv, kernel_size = 4):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size,kernel_size))\n",
    "    image_cv_dilated = cv2.dilate(image_cv, kernel)\n",
    "    return image_cv_dilated\n",
    "  if morph == 'dilate':\n",
    "    image_morphed = dilate(image,kernel_size = kernel_size)\n",
    "  elif morph == 'erode':\n",
    "    image_morphed = erosion(image,kernel_size = kernel_size)\n",
    "  else:\n",
    "    raise NotImplementedError\n",
    "  return image_morphed\n",
    "\n",
    "image_cv = cv2.imread(\"blob.png\", cv2.IMREAD_COLOR)\n",
    "image_cv_gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
    "_, image_binary = cv2.threshold(image_cv_gray, 0.0, 255.0, cv2.THRESH_BINARY)\n",
    "# image_morphed = morph_image(morph_image(image_binary,morph='erode', kernel_size=2),morph='dilate',kernel_size=10)\n",
    "image_morphed = morph_image(image_binary,morph='erode', kernel_size=100)\n",
    "morphed_contours = get_contours(image_morphed)\n",
    "image_cv_out = draw_contours(image_cv,morphed_contours,fill='solid')\n",
    "\n",
    "show_image(image_binary)\n",
    "print(\"\")\n",
    "show_image(image_cv_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fN3IcuP2mq72"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
